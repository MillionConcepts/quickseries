# quickseries

`quickseries` generates Python functions that perform fast vectorized power 
series approximations of locally-continuous univariate mathematical functions. 
`quickseries`is in alpha; bug reports are appreciated.

Install from source using `pip install .`. Dependencies are also described
in a Conda `environment.yml` file.

Further documentation forthcoming.

## example of use

```
>>> import numpy as np
>>> from quickseries import quickseries

>>> bounds = (-np.pi, np.pi)
>>> approx = quickseries("sin(x)*cos(x)", x0=0, n_terms=12, bounds=bounds)
>>> x = np.linspace(*bounds, 100000)
>>> print(f"max error: {max(abs(np.sin(x) * np.cos(x) - approx(x)))}")
>>> print("original runtime:")
>>> %timeit np.sin(x) * np.cos(x)
>>> print("approx runtime:")
>>> %timeit approx(x)

max error: 0.0003270875375037813
original runtime:
968 µs ± 2.17 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)
approx runtime:
325 µs ± 3.89 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)
```

## tips

* Narrowing `bounds` will tend to make the approximation more accurate within
those bounds. In the example above, setting `bounds` to `(-1, 1)` provides 
~20x greater precision within the (-1, 1) interval -- although the 
approximation will become very poor before it reaches +/- pi.
* Increasing `n_terms` will tend to make the approximation slower but more 
precise. In the example above, increasing `n_terms` to 14 provides ~20x 
greater precision but makes the approximation ~20% slower.
  * This tends to have diminishing returns. Increasing `n_terms` to 30 provides
  no meaningful increase in precision over 14 terms, but makes the 
  approximation *slower* than `np.sin(x) * np.cos(x)`.
  * Setting `n_terms` too high can also cause the approximation algorithm to
  fail entirely.
  * The location of precision/performance "sweet spots" in the parameter space 
  depends on the function and the approximation bounds. If you want to 
  seriously optimize a particular function in a particular interval, you will 
  need to play around with these parameters.
* The speedup (or lack thereof) that a `quickseries()`-generated approximation 
provides can vary greatly in different operating environments and on different 
processors.
* For most functions, placing `x0` in the middle of `bounds` will produce the
best results, and if you don't pass `x0` at all, `quickseries` defaults to 
placing it in the middle of `bounds`.
* Functions generated by `quickseries()` may in some cases be less 
space/memory-efficient even if they are more time/compute-efficient.
* By default, if you pass a simple polynomial expression to `quickseries()`
(e.g. `"x**4 + 2 * x**3"`), it does not actually generate an approximation, 
but instead simply attempts to rewrite it in a more efficient form.
    * `n_terms`, `bounds`, and `x0` are ignored in this "rewrite" mode.
    * This type of `quickseries()`-generated function should produce the same 
    results as any other Python function that straightforwardly implements a
    form of the input polynomial (down to floating-point error).
    * This can produce surprising speedups even in simple cases -- for example,
    `quickseries("x**4")` is ~20x faster than `lambda x: x ** 4` on some 
    `numpy` arrays.  
    * If you want `quickseries()` to actually create an approximation of a 
    simple polynomial, pass `approx_poly=True`.
      * If `n_terms` >= the order of the input polynomial, the 
      `quickseries()`-generated function will typically be very similar to a 
      simple rewrite of the input polynomial. `n_terms` effectively caps at the
      order of the input polynomial.
* At present, `quickseries()` only works on univariate functions that are 
locally continuous within `bounds`. It is also not guaranteed to work well, or 
at all, on all such functions within all intervals.
* `quickseries()` is also capable of auto-jitting the functions it generates
with `numba`. Pass the `jit=True` argument. `numba` is an optional dependency; 
install it with your preferred package manager.
  * In addition to the other inconveniences that may arise from just-in-time
  compilation, some functions that work well without `numba` may not work well
  with `numba`. However, it can provide a significant performance boost in some
  cases.